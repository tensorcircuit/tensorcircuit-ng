{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e5977f-d9dd-4f40-a086-6477799aa443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from functools import partial, reduce\n",
    "from operator import matmul, mul, or_\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Collection,\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from tensornetwork.network_components import AbstractNode, CopyNode, Edge, Node, connect\n",
    "from tensornetwork.network_operations import (\n",
    "    copy,\n",
    "    get_subgraph_dangling,\n",
    "    remove_node,\n",
    ")\n",
    "\n",
    "from tenpy.networks import MPO, MPS, Site\n",
    "from tenpy.linalg import np_conserved as npc\n",
    "from tenpy.linalg import LegCharge\n",
    "import tensornetwork as tn\n",
    "from quimb.tensor import MatrixProductOperator\n",
    "import quimb.tensor as qtn\n",
    "\n",
    "from tensorcircuit.cons import backend, contractor, dtypestr, npdtype, rdtypestr\n",
    "from tensorcircuit.gates import Gate, num_to_tensor\n",
    "from tensorcircuit.utils import arg_alias\n",
    "\n",
    "Tensor = Any\n",
    "Graph = Any\n",
    "\n",
    "from tenpy.models.tf_ising import TFIChain\n",
    "from tensorcircuit.quantum import QuOperator, quantum_constructor\n",
    "import tensorcircuit as tc\n",
    "import pytest\n",
    "from pytest_lazyfixture import lazy_fixture as lf\n",
    "\n",
    "import tensornetwork as tn\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "import tensornetwork as tn\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Demonstration of TeNPy-DMRG and TensorCircuit integration\n",
    "1. Compute ground state (MPS) of 1D Heisenberg model using TeNPy\n",
    "2. Convert MPS to TensorCircuit's QuOperator\n",
    "3. Initialize MPSCircuit with converted state and verify results\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union, Any\n",
    "from tenpy.networks.mps import MPS\n",
    "from tenpy.networks.mpo import MPO\n",
    "from tenpy.models.xxz_chain import XXZChain\n",
    "from tenpy.algorithms import dmrg\n",
    "import tensornetwork as tn\n",
    "\n",
    "import tensorcircuit as tc\n",
    "\n",
    "Node = tn.Node\n",
    "Edge = tn.Edge\n",
    "connect = tn.connect\n",
    "\n",
    "QuOperator = tc.quantum.QuOperator\n",
    "quantum_constructor = tc.quantum.quantum_constructor\n",
    "\n",
    "\n",
    "def tenpy2qop(tenpy_obj: Union[\"MPS\", \"MPO\"]) -> QuOperator:\n",
    "    \"\"\"\n",
    "    Converts a TeNPy MPO or MPS to a TensorCircuit QuOperator.\n",
    "    This definitive version correctly handles axis ordering and boundary\n",
    "    conditions to be compatible with `eval_matrix`.\n",
    "\n",
    "    :param tenpy_obj: A MPO or MPS object from the TeNPy package.\n",
    "    :type tenpy_obj: Union[tenpy.networks.mpo.MPO, tenpy.networks.mps.MPS]\n",
    "    :return: The corresponding state or operator as a QuOperator.\n",
    "    :rtype: QuOperator\n",
    "    \"\"\"\n",
    "    is_mpo = hasattr(tenpy_obj, \"_W\")\n",
    "    tenpy_tensors = tenpy_obj._W if is_mpo else tenpy_obj._B\n",
    "    nwires = len(tenpy_tensors)\n",
    "    if nwires == 0:\n",
    "        return quantum_constructor([], [], [])\n",
    "\n",
    "    nodes = []\n",
    "    if is_mpo:\n",
    "        vr_label, vl_label = \"wR\", \"wL\"\n",
    "        original_tensors = [W.to_ndarray() for W in tenpy_tensors]\n",
    "        modified_tensors = []\n",
    "\n",
    "        for i, (tensor, tenpy_t) in enumerate(zip(original_tensors, tenpy_tensors)):\n",
    "            labels = tenpy_t._labels\n",
    "            if nwires == 1:\n",
    "                tensor = np.take(tensor, [0], axis=labels.index(vl_label))\n",
    "                tensor = np.take(tensor, [-1], axis=labels.index(vr_label))\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    tensor = np.take(tensor, [0], axis=labels.index(vl_label))\n",
    "                elif i == nwires - 1:\n",
    "                    tensor = np.take(tensor, [-1], axis=labels.index(vr_label))\n",
    "            modified_tensors.append(tensor)\n",
    "\n",
    "        for i, t in enumerate(modified_tensors):\n",
    "            if t.ndim == 4:\n",
    "                t = t.transpose((0, 2, 3, 1))\n",
    "            nodes.append(\n",
    "                Node(t, name=f\"tensor_{i}\", axis_names=[\"wL\", \"p\", \"p*\", \"wR\"])\n",
    "            )\n",
    "\n",
    "        for i in range(nwires - 1):\n",
    "            connect(nodes[i][\"wR\"], nodes[i + 1][\"wL\"])\n",
    "\n",
    "        out_edges = [node[\"p*\"] for node in nodes]\n",
    "        in_edges = [node[\"p\"] for node in nodes]\n",
    "        ignore_edges = [nodes[0][\"wL\"], nodes[-1][\"wR\"]]\n",
    "    else:\n",
    "        nodes = [Node(W.to_ndarray()) for W in tenpy_tensors]\n",
    "        if nwires > 1:\n",
    "            for i in range(nwires - 1):\n",
    "                nodes[i][2] ^ nodes[i + 1][0]\n",
    "        out_edges = [n[1] for n in nodes]\n",
    "        in_edges = []\n",
    "        ignore_edges = [nodes[0][0], nodes[-1][2]]\n",
    "\n",
    "    qop = quantum_constructor(out_edges, in_edges, [], ignore_edges)\n",
    "\n",
    "    return qop\n",
    "\n",
    "\n",
    "def qop2tenpy(qop: QuOperator) -> Any:\n",
    "    \"\"\"\n",
    "    Convert TensorCircuit QuOperator to MPO or MPS from TeNPy.\n",
    "\n",
    "    :param qop: The corresponding state/operator as a QuOperator.\n",
    "    :return: MPO or MPS object from the TeNPy package.\n",
    "    :rtype: Union[tenpy.networks.mpo.MPO, tenpy.networks.mps.MPS]\n",
    "    \"\"\"\n",
    "    is_mps = len(qop.in_edges) == 0\n",
    "    nwires = len(qop.out_edges) if is_mps else len(qop.in_edges)\n",
    "\n",
    "    # Node sorting\n",
    "    endpoint_nodes = {edge.node1 for edge in qop.ignore_edges if edge.node1}\n",
    "    physical_edges = set(qop.in_edges + qop.out_edges)\n",
    "    if len(endpoint_nodes) < 2 and len(qop.ref_nodes) > 1:\n",
    "        inferred_endpoints = {\n",
    "            node\n",
    "            for node in qop.ref_nodes\n",
    "            if sum(1 for edge in node.edges if edge not in physical_edges) == 1\n",
    "        }\n",
    "        if len(inferred_endpoints) == 2:\n",
    "            endpoint_nodes = inferred_endpoints\n",
    "\n",
    "    # to correctly sort nodes\n",
    "    sorted_nodes: list[Node] = []\n",
    "    if endpoint_nodes:\n",
    "        current = next(iter(endpoint_nodes))\n",
    "        while current and len(sorted_nodes) < nwires:\n",
    "            sorted_nodes.append(current)\n",
    "            current = next(\n",
    "                (\n",
    "                    e.node2 if e.node1 is current else e.node1\n",
    "                    for e in current.edges\n",
    "                    if not e.is_dangling()\n",
    "                    and e not in physical_edges\n",
    "                    and (e.node2 if e.node1 is current else e.node1) not in sorted_nodes\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "\n",
    "    if not sorted_nodes:\n",
    "        sorted_nodes = qop.nodes\n",
    "\n",
    "    if len(sorted_nodes) > 0 and len(qop.ignore_edges) > 0:\n",
    "        if sorted_nodes[0] is not qop.ignore_edges[0].node1:\n",
    "            sorted_nodes = sorted_nodes[::-1]\n",
    "\n",
    "    physical_dim = qop.in_edges[0].dimension\n",
    "    sites = [Site(LegCharge.from_trivial(physical_dim), \"q\") for _ in range(nwires)]\n",
    "\n",
    "    # MPS Conversion\n",
    "    if is_mps:\n",
    "        tensors = []\n",
    "        for i, node in enumerate(sorted_nodes):\n",
    "            tensor = np.asarray(node.tensor)\n",
    "            if i == 0 and tensor.shape == (2, 2, 2):\n",
    "                tensor = tensor[0:1, :, :]\n",
    "            elif i == len(sorted_nodes) - 1 and tensor.shape == (2, 2, 2):\n",
    "                tensor = tensor[:, :, 0:1]\n",
    "            tensors.append(\n",
    "                npc.Array.from_ndarray(\n",
    "                    tensor,\n",
    "                    legcharges=[LegCharge.from_trivial(s) for s in tensor.shape],\n",
    "                    labels=[\"vL\", \"p\", \"vR\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        SVs = (\n",
    "            [np.ones([1])]\n",
    "            + [np.ones(tensors[i].get_leg(\"vR\").ind_len) for i in range(nwires - 1)]\n",
    "            + [np.ones([1])]\n",
    "        )\n",
    "        return MPS(sites, tensors, SVs, bc=\"finite\")\n",
    "\n",
    "    # MPO Conversion\n",
    "    raw_tensors = [np.asarray(node.tensor) for node in sorted_nodes]\n",
    "\n",
    "    chi = 1\n",
    "    if nwires > 1:\n",
    "        chi = raw_tensors[0].shape[3]\n",
    "\n",
    "    IdL = 0\n",
    "    IdR = chi - 1 if chi > 1 else 0\n",
    "\n",
    "    reconstructed_tensors = []\n",
    "\n",
    "    tensors_to_process = [t.copy() for t in raw_tensors]\n",
    "\n",
    "    if nwires > 0:\n",
    "        if tensors_to_process[0].shape[0] < chi:\n",
    "            t_left = tensors_to_process[0]\n",
    "            new_shape = (chi,) + t_left.shape[1:]\n",
    "            padded_left = np.zeros(new_shape, dtype=t_left.dtype)\n",
    "            padded_left[IdL, ...] = t_left[0, ...]\n",
    "            tensors_to_process[0] = padded_left\n",
    "\n",
    "        if tensors_to_process[-1].shape[3] < chi:\n",
    "            t_right = tensors_to_process[-1]\n",
    "            new_shape = t_right.shape[:3] + (chi,)\n",
    "            padded_right = np.zeros(new_shape, dtype=t_right.dtype)\n",
    "            padded_right[..., IdR] = t_right[..., 0]\n",
    "            tensors_to_process[-1] = padded_right\n",
    "\n",
    "    reconstructed_tensors = tensors_to_process\n",
    "\n",
    "    tenpy_Ws = []\n",
    "    for tensor in reconstructed_tensors:\n",
    "        labels = [\"wL\", \"wR\", \"p\", \"p*\"]\n",
    "        tensor = np.transpose(tensor, (0, 3, 1, 2))\n",
    "        tenpy_Ws.append(\n",
    "            npc.Array.from_ndarray(\n",
    "                tensor,\n",
    "                legcharges=[LegCharge.from_trivial(s) for s in tensor.shape],\n",
    "                labels=labels,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return MPO(sites, tenpy_Ws, bc=\"finite\", IdL=IdL, IdR=IdR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cd1a4-7741-48dc-8317-4761036b0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"backend\", [lf(\"npb\"), lf(\"tfb\"), lf(\"jaxb\")])\n",
    "def test_tenpy_roundtrip(backend):\n",
    "    try:\n",
    "        import tensornetwork as tn\n",
    "        from tenpy.networks.mps import MPS\n",
    "        from tenpy.networks.mpo import MPO\n",
    "        from tenpy.networks.site import Site\n",
    "        from tenpy.linalg.charges import LegCharge\n",
    "        from tenpy.linalg import np_conserved as npc\n",
    "    except ImportError:\n",
    "        pytest.skip(\"TeNPy or TensorNetwork is not installed\")\n",
    "\n",
    "    nwires_mpo = 3\n",
    "    chi_mpo = 4\n",
    "    phys_dim = 2\n",
    "    sites = [Site(LegCharge.from_trivial(phys_dim), \"q\") for _ in range(nwires_mpo)]\n",
    "    t_left = np.random.rand(1, chi_mpo, phys_dim, phys_dim)\n",
    "    Ws = [\n",
    "        npc.Array.from_ndarray(\n",
    "            t_left,\n",
    "            labels=[\"wL\", \"wR\", \"p\", \"p*\"],\n",
    "            legcharges=[LegCharge.from_trivial(s) for s in t_left.shape],\n",
    "        )\n",
    "    ]\n",
    "    for _ in range(nwires_mpo - 2):\n",
    "        t_bulk = np.random.rand(chi_mpo, chi_mpo, phys_dim, phys_dim)\n",
    "        Ws.append(\n",
    "            npc.Array.from_ndarray(\n",
    "                t_bulk,\n",
    "                labels=[\"wL\", \"wR\", \"p\", \"p*\"],\n",
    "                legcharges=[LegCharge.from_trivial(s) for s in t_bulk.shape],\n",
    "            )\n",
    "        )\n",
    "    t_right = np.random.rand(chi_mpo, 1, phys_dim, phys_dim)\n",
    "    Ws.append(\n",
    "        npc.Array.from_ndarray(\n",
    "            t_right,\n",
    "            labels=[\"wL\", \"wR\", \"p\", \"p*\"],\n",
    "            legcharges=[LegCharge.from_trivial(s) for s in t_right.shape],\n",
    "        )\n",
    "    )\n",
    "    mpo_original = MPO(sites, Ws, IdL=0, IdR=chi_mpo - 1)\n",
    "\n",
    "    qop_mpo = tc.quantum.tenpy2qop(mpo_original)\n",
    "    mpo_roundtrip = tc.quantum.qop2tenpy(qop_mpo)\n",
    "\n",
    "    try:\n",
    "        mat_original = mpo_original.to_matrix()\n",
    "        mat_roundtrip = mpo_roundtrip.to_matrix()\n",
    "    except AttributeError:\n",
    "        # Inlined logic for mpo_original\n",
    "        contraction_nodes_orig = []\n",
    "        canonical_order_orig = [\"wL\", \"wR\", \"p\", \"p*\"]\n",
    "        for i in range(mpo_original.L):\n",
    "            W_tenpy_array = mpo_original.get_W(i)\n",
    "            W_transposed = W_tenpy_array.itranspose(canonical_order_orig)\n",
    "            contraction_nodes_orig.append(tn.Node(W_transposed.to_ndarray()))\n",
    "        for i in range(mpo_original.L - 1):\n",
    "            contraction_nodes_orig[i][1] ^ contraction_nodes_orig[i + 1][0]\n",
    "        chi_left_orig = contraction_nodes_orig[0].shape[0]\n",
    "        chi_right_orig = contraction_nodes_orig[-1].shape[1]\n",
    "        left_bc_vec_orig = np.zeros(chi_left_orig)\n",
    "        left_idx_orig = 0 if chi_left_orig == 1 else mpo_original.IdL\n",
    "        left_bc_vec_orig[left_idx_orig] = 1.0\n",
    "        right_bc_vec_orig = np.zeros(chi_right_orig)\n",
    "        right_idx_orig = 0 if chi_right_orig == 1 else mpo_original.IdR\n",
    "        right_bc_vec_orig[right_idx_orig] = 1.0\n",
    "        left_node_orig = tn.Node(left_bc_vec_orig)\n",
    "        right_node_orig = tn.Node(right_bc_vec_orig)\n",
    "        contraction_nodes_orig[0][0] ^ left_node_orig[0]\n",
    "        contraction_nodes_orig[-1][1] ^ right_node_orig[0]\n",
    "        output_edges_orig = [node[3] for node in contraction_nodes_orig]\n",
    "        input_edges_orig = [node[2] for node in contraction_nodes_orig]\n",
    "        result_node_orig = tn.contractors.auto(\n",
    "            contraction_nodes_orig + [left_node_orig, right_node_orig],\n",
    "            output_edge_order=output_edges_orig + input_edges_orig,\n",
    "        )\n",
    "        D_orig = np.prod(mpo_original.dim)\n",
    "        mat_original = tc.backend.reshape(result_node_orig.tensor, (D_orig, D_orig))\n",
    "\n",
    "        # Inlined logic for mpo_roundtrip\n",
    "        contraction_nodes_rt = []\n",
    "        canonical_order_rt = [\"wL\", \"wR\", \"p\", \"p*\"]\n",
    "        for i in range(mpo_roundtrip.L):\n",
    "            W_tenpy_array_rt = mpo_roundtrip.get_W(i)\n",
    "            W_transposed_rt = W_tenpy_array_rt.itranspose(canonical_order_rt)\n",
    "            contraction_nodes_rt.append(tn.Node(W_transposed_rt.to_ndarray()))\n",
    "        for i in range(mpo_roundtrip.L - 1):\n",
    "            contraction_nodes_rt[i][1] ^ contraction_nodes_rt[i + 1][0]\n",
    "        chi_left_rt = contraction_nodes_rt[0].shape[0]\n",
    "        chi_right_rt = contraction_nodes_rt[-1].shape[1]\n",
    "        left_bc_vec_rt = np.zeros(chi_left_rt)\n",
    "        left_idx_rt = 0 if chi_left_rt == 1 else mpo_roundtrip.IdL\n",
    "        left_bc_vec_rt[left_idx_rt] = 1.0\n",
    "        right_bc_vec_rt = np.zeros(chi_right_rt)\n",
    "        right_idx_rt = 0 if chi_right_rt == 1 else mpo_roundtrip.IdR\n",
    "        right_bc_vec_rt[right_idx_rt] = 1.0\n",
    "        left_node_rt = tn.Node(left_bc_vec_rt)\n",
    "        right_node_rt = tn.Node(right_bc_vec_rt)\n",
    "        contraction_nodes_rt[0][0] ^ left_node_rt[0]\n",
    "        contraction_nodes_rt[-1][1] ^ right_node_rt[0]\n",
    "        output_edges_rt = [node[3] for node in contraction_nodes_rt]\n",
    "        input_edges_rt = [node[2] for node in contraction_nodes_rt]\n",
    "        result_node_rt = tn.contractors.auto(\n",
    "            contraction_nodes_rt + [left_node_rt, right_node_rt],\n",
    "            output_edge_order=output_edges_rt + input_edges_rt,\n",
    "        )\n",
    "        D_rt = np.prod(mpo_roundtrip.dim)\n",
    "        mat_roundtrip = tc.backend.reshape(result_node_rt.tensor, (D_rt, D_rt))\n",
    "\n",
    "    np.testing.assert_allclose(mat_original, mat_roundtrip, atol=1e-5)\n",
    "\n",
    "    # MPS roundtrip\n",
    "    nwires_mps = 4\n",
    "    chi_mps = 5\n",
    "    sites_mps = [Site(LegCharge.from_trivial(phys_dim), \"q\") for _ in range(nwires_mps)]\n",
    "    b_left = np.random.rand(1, phys_dim, chi_mps)\n",
    "    Bs = [\n",
    "        npc.Array.from_ndarray(\n",
    "            b_left,\n",
    "            labels=[\"vL\", \"p\", \"vR\"],\n",
    "            legcharges=[LegCharge.from_trivial(s) for s in b_left.shape],\n",
    "        )\n",
    "    ]\n",
    "    for _ in range(nwires_mps - 2):\n",
    "        b_bulk = np.random.rand(chi_mps, phys_dim, chi_mps)\n",
    "        Bs.append(\n",
    "            npc.Array.from_ndarray(\n",
    "                b_bulk,\n",
    "                labels=[\"vL\", \"p\", \"vR\"],\n",
    "                legcharges=[LegCharge.from_trivial(s) for s in b_bulk.shape],\n",
    "            )\n",
    "        )\n",
    "    b_right = np.random.rand(chi_mps, phys_dim, 1)\n",
    "    Bs.append(\n",
    "        npc.Array.from_ndarray(\n",
    "            b_right,\n",
    "            labels=[\"vL\", \"p\", \"vR\"],\n",
    "            legcharges=[LegCharge.from_trivial(s) for s in b_right.shape],\n",
    "        )\n",
    "    )\n",
    "    SVs = [np.ones([1])]\n",
    "    for B in Bs[:-1]:\n",
    "        sv_dim = B.get_leg(\"vR\").ind_len\n",
    "        SVs.append(np.ones(sv_dim))\n",
    "    SVs.append(np.ones([1]))\n",
    "    mps_original = MPS(sites_mps, Bs, SVs)\n",
    "\n",
    "    qop_mps = tc.quantum.tenpy2qop(mps_original)\n",
    "    mps_roundtrip = tc.quantum.qop2tenpy(qop_mps)\n",
    "\n",
    "    try:\n",
    "        vec_original = mps_original.to_ndarray()\n",
    "        vec_roundtrip = mps_roundtrip.to_ndarray()\n",
    "    except AttributeError:\n",
    "        full_theta_orig = mps_original.get_theta(0, mps_original.L)\n",
    "        state_tensor_orig = full_theta_orig.to_ndarray()\n",
    "        vec_original = state_tensor_orig.reshape(-1)\n",
    "\n",
    "        full_theta_rt = mps_roundtrip.get_theta(0, mps_roundtrip.L)\n",
    "        state_tensor_rt = full_theta_rt.to_ndarray()\n",
    "        vec_roundtrip = state_tensor_rt.reshape(-1)\n",
    "\n",
    "    np.testing.assert_allclose(vec_original, vec_roundtrip, atol=1e-5)\n",
    "\n",
    "\n",
    "test_tenpy_roundtrip(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffbd13-84d3-4b35-b9c2-9cd6e76c9c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
